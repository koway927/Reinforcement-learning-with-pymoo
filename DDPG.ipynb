{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "from pymoo.core.algorithm import Algorithm\n",
    "from pymoo.operators.sampling.rnd import FloatRandomSampling\n",
    "from torch.distributions import Normal, Uniform\n",
    "from pymoo.core.initialization import Initialization\n",
    "from pymoo.algorithms.moo.nsga2 import RankAndCrowdingSurvival\n",
    "from pymoo.operators.crossover.sbx import SimulatedBinaryCrossover\n",
    "from pymoo.core.population import Population\n",
    "from pymoo.operators.repair.bounds_repair import is_out_of_bounds_by_problem\n",
    "from pymoo.core.repair import NoRepair\n",
    "from torch import optim\n",
    "import torch\n",
    "import numpy as np\n",
    "from pymoo.util.optimum import filter_optimum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] WARNING: this method is DEPRECATED and has no effect, please remove it from your code.\n",
      "[TL] Input  A_input: [None, array(13)]\n",
      "[TL] Dense  A_l1: 13 relu\n",
      "[TL] Dense  A_l2: 13 relu\n",
      "[TL] Dense  A_a: 13 tanh\n",
      "[TL] Lambda  lambda_18: func: <function Deep_Deterministic_policy_gradient.get_actor.<locals>.<lambda> at 0x7f36fbc5f310>, len_weights: 0\n",
      "[TL] WARNING: this method is DEPRECATED and has no effect, please remove it from your code.\n",
      "[TL] Input  C_s_input: [None, array(13)]\n",
      "[TL] Input  C_a_input: [None, array(13)]\n",
      "[TL] Concat concat_11: concat_dim: 1\n",
      "[TL] Dense  C_l1: 13 relu\n",
      "[TL] Dense  C_l2: 13 relu\n",
      "[TL] Dense  C_out: 1 No Activation\n",
      "[TL] WARNING: this method is DEPRECATED and has no effect, please remove it from your code.\n",
      "[TL] Input  A_input: [None, array(13)]\n",
      "[TL] Dense  A_l1: 13 relu\n",
      "[TL] Dense  A_l2: 13 relu\n",
      "[TL] Dense  A_a: 13 tanh\n",
      "[TL] Lambda  lambda_19: func: <function Deep_Deterministic_policy_gradient.get_actor.<locals>.<lambda> at 0x7f36fbe80940>, len_weights: 0\n",
      "[TL] WARNING: this method is DEPRECATED and has no effect, please remove it from your code.\n",
      "[TL] Input  C_s_input: [None, array(13)]\n",
      "[TL] Input  C_a_input: [None, array(13)]\n",
      "[TL] Concat concat_12: concat_dim: 1\n",
      "[TL] Dense  C_l1: 13 relu\n",
      "[TL] Dense  C_l2: 13 relu\n",
      "[TL] Dense  C_out: 1 No Activation\n",
      "[TL] Input  r: [None, 1]\n",
      "Episode: 2 --- Rewards: [-1880.90889385] --- Steps: 20\n",
      "Episode: 3 --- Rewards: [-6154.62972395] --- Steps: 20\n",
      "Episode: 4 --- Rewards: [-2938.64208735] --- Steps: 20\n",
      "Episode: 5 --- Rewards: [-683.42598483] --- Steps: 20\n",
      "Episode: 6 --- Rewards: [-3277.07177745] --- Steps: 20\n",
      "Episode: 7 --- Rewards: [-5414.53054623] --- Steps: 20\n",
      "Episode: 8 --- Rewards: [-6097.71290621] --- Steps: 20\n",
      "Episode: 9 --- Rewards: [-2873.7029681] --- Steps: 20\n",
      "Episode: 10 --- Rewards: [-3967.04700075] --- Steps: 20\n",
      "Episode: 11 --- Rewards: [-1028.08611916] --- Steps: 20\n",
      "Episode: 12 --- Rewards: [-3137.23993881] --- Steps: 20\n",
      "Episode: 13 --- Rewards: [-1934.86590986] --- Steps: 20\n",
      "Episode: 14 --- Rewards: [-2264.96959051] --- Steps: 20\n",
      "Episode: 15 --- Rewards: [-2182.63883166] --- Steps: 20\n",
      "Episode: 16 --- Rewards: [-4848.68251552] --- Steps: 20\n",
      "Episode: 17 --- Rewards: [-1312.31332357] --- Steps: 20\n",
      "Episode: 18 --- Rewards: [-8375.14725873] --- Steps: 20\n",
      "Episode: 19 --- Rewards: [-7979.8614469] --- Steps: 20\n",
      "Episode: 20 --- Rewards: [-4671.06189231] --- Steps: 20\n",
      "Episode: 21 --- Rewards: [-5252.82769011] --- Steps: 20\n",
      "Episode: 22 --- Rewards: [-4278.62925323] --- Steps: 20\n",
      "Episode: 23 --- Rewards: [-6023.82932918] --- Steps: 20\n",
      "Episode: 24 --- Rewards: [-7866.28221417] --- Steps: 20\n",
      "Episode: 25 --- Rewards: [-4366.82160914] --- Steps: 20\n",
      "Episode: 26 --- Rewards: [-2232.50025573] --- Steps: 20\n",
      "Episode: 27 --- Rewards: [-320.98421388] --- Steps: 20\n",
      "Episode: 28 --- Rewards: [-4190.01908864] --- Steps: 20\n",
      "Episode: 29 --- Rewards: [-5134.46588313] --- Steps: 20\n",
      "Episode: 30 --- Rewards: [-3684.27254672] --- Steps: 20\n",
      "Episode: 31 --- Rewards: [-4378.11848937] --- Steps: 20\n",
      "Episode: 32 --- Rewards: [-5806.1326602] --- Steps: 20\n",
      "Episode: 33 --- Rewards: [-2885.57451543] --- Steps: 20\n",
      "Episode: 34 --- Rewards: [-2997.25101589] --- Steps: 20\n",
      "Episode: 35 --- Rewards: [-1991.24237454] --- Steps: 20\n",
      "Episode: 36 --- Rewards: [-1908.95020546] --- Steps: 20\n",
      "Episode: 37 --- Rewards: [-7482.19964093] --- Steps: 20\n",
      "Episode: 38 --- Rewards: [-3447.18354168] --- Steps: 20\n",
      "Episode: 39 --- Rewards: [-1623.26860773] --- Steps: 20\n",
      "Episode: 40 --- Rewards: [-5250.39644091] --- Steps: 20\n",
      "Episode: 41 --- Rewards: [-4670.39203699] --- Steps: 20\n",
      "Episode: 42 --- Rewards: [-15530.79197049] --- Steps: 20\n",
      "Episode: 43 --- Rewards: [-3034.34074637] --- Steps: 20\n",
      "Episode: 44 --- Rewards: [-2982.46908314] --- Steps: 20\n",
      "Episode: 45 --- Rewards: [-1120.28798276] --- Steps: 20\n",
      "Episode: 46 --- Rewards: [-6953.18966288] --- Steps: 20\n",
      "Episode: 47 --- Rewards: [-7151.61740225] --- Steps: 20\n",
      "Episode: 48 --- Rewards: [-2447.21808971] --- Steps: 20\n",
      "Episode: 49 --- Rewards: [-1915.79730451] --- Steps: 20\n",
      "Episode: 50 --- Rewards: [-3611.37331147] --- Steps: 20\n",
      "Episode: 51 --- Rewards: [-3945.75387981] --- Steps: 20\n",
      "Episode: 52 --- Rewards: [-732.61428838] --- Steps: 20\n",
      "Episode: 53 --- Rewards: [-1867.89449075] --- Steps: 20\n",
      "Episode: 54 --- Rewards: [-2110.26170567] --- Steps: 20\n",
      "Episode: 55 --- Rewards: [-1024.06584914] --- Steps: 20\n",
      "Episode: 56 --- Rewards: [-1595.90972679] --- Steps: 20\n",
      "Episode: 57 --- Rewards: [-2364.28921292] --- Steps: 20\n",
      "Episode: 58 --- Rewards: [-4441.57251621] --- Steps: 20\n",
      "Episode: 59 --- Rewards: [-8006.45535645] --- Steps: 20\n",
      "Episode: 60 --- Rewards: [-4753.86800259] --- Steps: 20\n",
      "Episode: 61 --- Rewards: [-4794.83804678] --- Steps: 20\n",
      "Episode: 62 --- Rewards: [-7598.63385554] --- Steps: 20\n",
      "Episode: 63 --- Rewards: [-3168.84864993] --- Steps: 20\n",
      "Episode: 64 --- Rewards: [-5618.20371552] --- Steps: 20\n",
      "Episode: 65 --- Rewards: [-1998.87494708] --- Steps: 20\n",
      "Episode: 66 --- Rewards: [-14701.59338662] --- Steps: 20\n",
      "Episode: 67 --- Rewards: [-6322.95698484] --- Steps: 20\n",
      "Episode: 68 --- Rewards: [-867.24138773] --- Steps: 20\n",
      "Episode: 69 --- Rewards: [-4191.62329468] --- Steps: 20\n",
      "Episode: 70 --- Rewards: [-9731.21238501] --- Steps: 20\n",
      "Episode: 71 --- Rewards: [-5886.24597205] --- Steps: 20\n",
      "Episode: 72 --- Rewards: [-3106.13831055] --- Steps: 20\n",
      "Episode: 73 --- Rewards: [-5078.63382356] --- Steps: 20\n",
      "Episode: 74 --- Rewards: [-3059.65946727] --- Steps: 20\n",
      "Episode: 75 --- Rewards: [-6744.60013802] --- Steps: 20\n",
      "Episode: 76 --- Rewards: [-5345.28874285] --- Steps: 20\n",
      "Episode: 77 --- Rewards: [-5063.48636426] --- Steps: 20\n",
      "Episode: 78 --- Rewards: [-4456.33054555] --- Steps: 20\n",
      "Episode: 79 --- Rewards: [-3979.33558629] --- Steps: 20\n",
      "Episode: 80 --- Rewards: [-4081.27702963] --- Steps: 20\n",
      "Episode: 81 --- Rewards: [-5014.44156568] --- Steps: 20\n",
      "Episode: 82 --- Rewards: [-2853.72874287] --- Steps: 20\n",
      "Episode: 83 --- Rewards: [-3637.11880625] --- Steps: 20\n",
      "Episode: 84 --- Rewards: [-7436.54163578] --- Steps: 20\n",
      "Episode: 85 --- Rewards: [-1080.91858049] --- Steps: 20\n",
      "Episode: 86 --- Rewards: [-1389.83627925] --- Steps: 20\n",
      "Episode: 87 --- Rewards: [-6234.4414463] --- Steps: 20\n",
      "Episode: 88 --- Rewards: [-4202.66077183] --- Steps: 20\n",
      "Episode: 89 --- Rewards: [-832.26279992] --- Steps: 20\n",
      "Episode: 90 --- Rewards: [-3830.51341981] --- Steps: 20\n",
      "Episode: 91 --- Rewards: [-2716.82653998] --- Steps: 20\n",
      "Episode: 92 --- Rewards: [-6915.96457634] --- Steps: 20\n",
      "Episode: 93 --- Rewards: [-2250.18254472] --- Steps: 20\n",
      "Episode: 94 --- Rewards: [-4541.97330816] --- Steps: 20\n",
      "Episode: 95 --- Rewards: [-4978.85486868] --- Steps: 20\n",
      "Episode: 96 --- Rewards: [-3406.43094774] --- Steps: 20\n",
      "Episode: 97 --- Rewards: [-3108.23105712] --- Steps: 20\n",
      "Episode: 98 --- Rewards: [-2702.19913401] --- Steps: 20\n",
      "Episode: 99 --- Rewards: [-11483.63510844] --- Steps: 20\n",
      "Episode: 100 --- Rewards: [-3526.6837214] --- Steps: 20\n",
      "Episode: 101 --- Rewards: [-4542.59196179] --- Steps: 20\n",
      "Episode: 102 --- Rewards: [-4473.8131771] --- Steps: 20\n",
      "Episode: 103 --- Rewards: [-11564.84406401] --- Steps: 20\n",
      "Episode: 104 --- Rewards: [-9619.79239556] --- Steps: 20\n",
      "Episode: 105 --- Rewards: [-2474.1290669] --- Steps: 20\n",
      "Episode: 106 --- Rewards: [-7732.8882923] --- Steps: 20\n",
      "Episode: 107 --- Rewards: [-3783.63562784] --- Steps: 20\n",
      "Episode: 108 --- Rewards: [-3932.69215202] --- Steps: 20\n",
      "Episode: 109 --- Rewards: [-1884.48908515] --- Steps: 20\n",
      "Episode: 110 --- Rewards: [-5383.28342587] --- Steps: 20\n",
      "Episode: 111 --- Rewards: [-10831.39975965] --- Steps: 20\n",
      "Episode: 112 --- Rewards: [-2514.92869569] --- Steps: 20\n",
      "Episode: 113 --- Rewards: [-2917.50434594] --- Steps: 20\n",
      "Episode: 114 --- Rewards: [-526.17262136] --- Steps: 20\n",
      "Episode: 115 --- Rewards: [-2692.41594737] --- Steps: 20\n",
      "Episode: 116 --- Rewards: [-5886.1143018] --- Steps: 20\n",
      "Episode: 117 --- Rewards: [-1778.05395329] --- Steps: 20\n",
      "Episode: 118 --- Rewards: [-7128.26174658] --- Steps: 20\n",
      "Episode: 119 --- Rewards: [-18727.4625814] --- Steps: 20\n",
      "Episode: 120 --- Rewards: [-6187.48661337] --- Steps: 20\n",
      "Episode: 121 --- Rewards: [-4690.92153651] --- Steps: 20\n",
      "Episode: 122 --- Rewards: [-1863.64648535] --- Steps: 20\n",
      "Episode: 123 --- Rewards: [-4584.71373081] --- Steps: 20\n",
      "Episode: 124 --- Rewards: [-1613.61090315] --- Steps: 20\n",
      "Episode: 125 --- Rewards: [-5151.46850245] --- Steps: 20\n",
      "Episode: 126 --- Rewards: [-11315.93440888] --- Steps: 20\n",
      "Episode: 127 --- Rewards: [-2752.54385873] --- Steps: 20\n",
      "Episode: 128 --- Rewards: [-3094.21463231] --- Steps: 20\n",
      "Episode: 129 --- Rewards: [-4342.501769] --- Steps: 20\n",
      "Episode: 130 --- Rewards: [-1876.72662841] --- Steps: 20\n",
      "Episode: 131 --- Rewards: [-1482.03635114] --- Steps: 20\n",
      "Episode: 132 --- Rewards: [-2678.23289438] --- Steps: 20\n",
      "Episode: 133 --- Rewards: [-3663.24180987] --- Steps: 20\n",
      "Episode: 134 --- Rewards: [-5110.82299627] --- Steps: 20\n",
      "Episode: 135 --- Rewards: [-3774.3843733] --- Steps: 20\n",
      "Episode: 136 --- Rewards: [-1928.26883218] --- Steps: 20\n",
      "Episode: 137 --- Rewards: [-2670.04020919] --- Steps: 20\n",
      "Episode: 138 --- Rewards: [-5507.07903951] --- Steps: 20\n",
      "Episode: 139 --- Rewards: [-860.326708] --- Steps: 20\n",
      "Episode: 140 --- Rewards: [-5365.77357052] --- Steps: 20\n",
      "Episode: 141 --- Rewards: [-9610.61837595] --- Steps: 20\n",
      "Episode: 142 --- Rewards: [-1553.57088907] --- Steps: 20\n",
      "Episode: 143 --- Rewards: [-2869.30215009] --- Steps: 20\n",
      "Episode: 144 --- Rewards: [-17092.20674364] --- Steps: 20\n",
      "Episode: 145 --- Rewards: [-1044.27372336] --- Steps: 20\n",
      "Episode: 146 --- Rewards: [-2514.40165642] --- Steps: 20\n",
      "Episode: 147 --- Rewards: [-6304.79602447] --- Steps: 20\n",
      "Episode: 148 --- Rewards: [-6812.09822886] --- Steps: 20\n",
      "Episode: 149 --- Rewards: [-1189.51369889] --- Steps: 20\n",
      "Episode: 150 --- Rewards: [-2518.48278874] --- Steps: 20\n",
      "Episode: 151 --- Rewards: [-5583.71768526] --- Steps: 20\n",
      "Episode: 152 --- Rewards: [-8576.82142336] --- Steps: 20\n",
      "Episode: 153 --- Rewards: [-4895.37137957] --- Steps: 20\n",
      "Episode: 154 --- Rewards: [-7381.80217711] --- Steps: 20\n",
      "Episode: 155 --- Rewards: [-2865.48571923] --- Steps: 20\n",
      "Episode: 156 --- Rewards: [-5474.38015725] --- Steps: 20\n",
      "Episode: 157 --- Rewards: [-558.64676663] --- Steps: 20\n",
      "Episode: 158 --- Rewards: [-3183.37487325] --- Steps: 20\n",
      "Episode: 159 --- Rewards: [-7697.34546082] --- Steps: 20\n",
      "Episode: 160 --- Rewards: [-7402.12141101] --- Steps: 20\n",
      "Episode: 161 --- Rewards: [-2306.13677361] --- Steps: 20\n",
      "Episode: 162 --- Rewards: [-17386.0258345] --- Steps: 20\n",
      "Episode: 163 --- Rewards: [-5267.43200615] --- Steps: 20\n",
      "Episode: 164 --- Rewards: [-576.93149266] --- Steps: 20\n",
      "Episode: 165 --- Rewards: [-1912.92523949] --- Steps: 20\n",
      "Episode: 166 --- Rewards: [-786.35959876] --- Steps: 20\n",
      "Episode: 167 --- Rewards: [-4140.15397434] --- Steps: 20\n",
      "Episode: 168 --- Rewards: [-8325.3737947] --- Steps: 20\n",
      "Episode: 169 --- Rewards: [-788.452341] --- Steps: 20\n",
      "Episode: 170 --- Rewards: [-9397.89339098] --- Steps: 20\n",
      "Episode: 171 --- Rewards: [-4528.19800561] --- Steps: 20\n",
      "Episode: 172 --- Rewards: [-11721.00117451] --- Steps: 20\n",
      "Episode: 173 --- Rewards: [-12391.44184265] --- Steps: 20\n",
      "Episode: 174 --- Rewards: [-11379.09522025] --- Steps: 20\n",
      "Episode: 175 --- Rewards: [-1882.03919071] --- Steps: 20\n",
      "Episode: 176 --- Rewards: [-2299.55376397] --- Steps: 20\n",
      "Episode: 177 --- Rewards: [-4749.91843743] --- Steps: 20\n",
      "Episode: 178 --- Rewards: [-1289.88612506] --- Steps: 20\n",
      "Episode: 179 --- Rewards: [-6431.88407243] --- Steps: 20\n",
      "Episode: 180 --- Rewards: [-624.05039012] --- Steps: 20\n",
      "Episode: 181 --- Rewards: [-3460.0703585] --- Steps: 20\n",
      "Episode: 182 --- Rewards: [-4393.20766089] --- Steps: 20\n",
      "Episode: 183 --- Rewards: [-199.82688719] --- Steps: 20\n",
      "Episode: 184 --- Rewards: [-5881.10701119] --- Steps: 20\n",
      "Episode: 185 --- Rewards: [-2105.68590026] --- Steps: 20\n",
      "Episode: 186 --- Rewards: [-1638.52690525] --- Steps: 20\n",
      "Episode: 187 --- Rewards: [-5781.88525915] --- Steps: 20\n",
      "Episode: 188 --- Rewards: [-3833.9426632] --- Steps: 20\n",
      "Episode: 189 --- Rewards: [-4072.06289688] --- Steps: 20\n",
      "Episode: 190 --- Rewards: [-8131.5950101] --- Steps: 20\n",
      "Episode: 191 --- Rewards: [-7425.70384033] --- Steps: 20\n",
      "Episode: 192 --- Rewards: [-6142.96602517] --- Steps: 20\n",
      "Episode: 193 --- Rewards: [-5145.06176354] --- Steps: 20\n",
      "Episode: 194 --- Rewards: [-1302.26897071] --- Steps: 20\n",
      "Episode: 195 --- Rewards: [-3230.58305176] --- Steps: 20\n",
      "Episode: 196 --- Rewards: [-3895.43494475] --- Steps: 20\n",
      "Episode: 197 --- Rewards: [-4396.61217707] --- Steps: 20\n",
      "Episode: 198 --- Rewards: [-3849.26087011] --- Steps: 20\n",
      "Episode: 199 --- Rewards: [-3183.47443547] --- Steps: 20\n",
      "Episode: 200 --- Rewards: [-5952.27210885] --- Steps: 20\n",
      "Episode: 201 --- Rewards: [-5530.38950451] --- Steps: 20\n",
      "Episode: 202 --- Rewards: [-9066.37790047] --- Steps: 20\n",
      "Episode: 203 --- Rewards: [-3602.94314267] --- Steps: 20\n",
      "Episode: 204 --- Rewards: [-7037.60801855] --- Steps: 20\n",
      "Episode: 205 --- Rewards: [-4381.92531557] --- Steps: 20\n",
      "Episode: 206 --- Rewards: [-928.80572327] --- Steps: 20\n",
      "Episode: 207 --- Rewards: [-4003.46329063] --- Steps: 20\n",
      "Episode: 208 --- Rewards: [-4501.99681396] --- Steps: 20\n",
      "Episode: 209 --- Rewards: [-3492.85705684] --- Steps: 20\n",
      "Episode: 210 --- Rewards: [-1409.47613676] --- Steps: 20\n",
      "Episode: 211 --- Rewards: [-10159.98395073] --- Steps: 20\n",
      "Episode: 212 --- Rewards: [-3098.09867842] --- Steps: 20\n",
      "Episode: 213 --- Rewards: [-12999.63973546] --- Steps: 20\n",
      "Episode: 214 --- Rewards: [-1915.93510204] --- Steps: 20\n",
      "Episode: 215 --- Rewards: [-414.90442984] --- Steps: 20\n",
      "Episode: 216 --- Rewards: [-2740.47661674] --- Steps: 20\n",
      "Episode: 217 --- Rewards: [-7525.19858765] --- Steps: 20\n",
      "Episode: 218 --- Rewards: [-665.00608038] --- Steps: 20\n",
      "Episode: 219 --- Rewards: [-3918.96065483] --- Steps: 20\n",
      "Episode: 220 --- Rewards: [-2316.12751132] --- Steps: 20\n",
      "Episode: 221 --- Rewards: [-3933.4885314] --- Steps: 20\n",
      "Episode: 222 --- Rewards: [-7102.9991967] --- Steps: 20\n",
      "Episode: 223 --- Rewards: [-6284.11293852] --- Steps: 20\n",
      "Episode: 224 --- Rewards: [-11666.21478541] --- Steps: 20\n",
      "Episode: 225 --- Rewards: [-8662.29362155] --- Steps: 20\n",
      "Episode: 226 --- Rewards: [-7221.58550397] --- Steps: 20\n",
      "Episode: 227 --- Rewards: [-5347.49671696] --- Steps: 20\n",
      "Episode: 228 --- Rewards: [-443.67755228] --- Steps: 20\n",
      "Episode: 229 --- Rewards: [-4629.60342958] --- Steps: 20\n",
      "Episode: 230 --- Rewards: [-6120.82816549] --- Steps: 20\n",
      "Episode: 231 --- Rewards: [-8362.81205016] --- Steps: 20\n",
      "Episode: 232 --- Rewards: [-10236.54181556] --- Steps: 20\n",
      "Episode: 233 --- Rewards: [-228.45695875] --- Steps: 20\n",
      "Episode: 234 --- Rewards: [-2119.84474586] --- Steps: 20\n",
      "Episode: 235 --- Rewards: [-3954.71961761] --- Steps: 20\n",
      "Episode: 236 --- Rewards: [-3566.69109039] --- Steps: 20\n",
      "Episode: 237 --- Rewards: [-5287.09895973] --- Steps: 20\n",
      "Episode: 238 --- Rewards: [-4815.36758902] --- Steps: 20\n",
      "Episode: 239 --- Rewards: [-641.88337255] --- Steps: 20\n",
      "Episode: 240 --- Rewards: [-4163.83591111] --- Steps: 20\n",
      "Episode: 241 --- Rewards: [-4525.58936028] --- Steps: 20\n",
      "Episode: 242 --- Rewards: [-5392.58241753] --- Steps: 20\n",
      "Episode: 243 --- Rewards: [-3008.24038775] --- Steps: 20\n",
      "Episode: 244 --- Rewards: [-1504.08036277] --- Steps: 20\n",
      "Episode: 245 --- Rewards: [-2057.92112067] --- Steps: 20\n",
      "Episode: 246 --- Rewards: [-8158.1445812] --- Steps: 20\n",
      "Episode: 247 --- Rewards: [-2994.74638062] --- Steps: 20\n",
      "Episode: 248 --- Rewards: [-1527.80751637] --- Steps: 20\n",
      "Episode: 249 --- Rewards: [-6880.34114441] --- Steps: 20\n",
      "Episode: 250 --- Rewards: [-3126.99314794] --- Steps: 20\n",
      "Episode: 251 --- Rewards: [-1150.09243324] --- Steps: 20\n",
      "Episode: 252 --- Rewards: [-4521.32341284] --- Steps: 20\n",
      "Episode: 253 --- Rewards: [-4185.08144679] --- Steps: 20\n",
      "Episode: 254 --- Rewards: [-9513.17947917] --- Steps: 20\n",
      "Episode: 255 --- Rewards: [-8948.41971255] --- Steps: 20\n",
      "Episode: 256 --- Rewards: [-6607.50344064] --- Steps: 20\n",
      "Episode: 257 --- Rewards: [-7261.03382912] --- Steps: 20\n",
      "Episode: 258 --- Rewards: [-2653.6394695] --- Steps: 20\n",
      "Episode: 259 --- Rewards: [-1977.41881466] --- Steps: 20\n",
      "Episode: 260 --- Rewards: [-3513.10827984] --- Steps: 20\n",
      "Episode: 261 --- Rewards: [-2585.54845746] --- Steps: 20\n",
      "Episode: 262 --- Rewards: [-4907.88875958] --- Steps: 20\n",
      "Episode: 263 --- Rewards: [-4576.32421341] --- Steps: 20\n",
      "Episode: 264 --- Rewards: [-3996.36244147] --- Steps: 20\n",
      "Episode: 265 --- Rewards: [-7424.37426792] --- Steps: 20\n",
      "Episode: 266 --- Rewards: [-8033.72512718] --- Steps: 20\n",
      "Episode: 267 --- Rewards: [-7881.26499978] --- Steps: 20\n",
      "Episode: 268 --- Rewards: [-6003.49577385] --- Steps: 20\n",
      "Episode: 269 --- Rewards: [-2459.27870297] --- Steps: 20\n",
      "Episode: 270 --- Rewards: [-4857.42436316] --- Steps: 20\n",
      "Episode: 271 --- Rewards: [-1461.40808708] --- Steps: 20\n",
      "Episode: 272 --- Rewards: [-3533.0806945] --- Steps: 20\n",
      "Episode: 273 --- Rewards: [-2986.00835586] --- Steps: 20\n",
      "Episode: 274 --- Rewards: [-5339.48564946] --- Steps: 20\n",
      "Episode: 275 --- Rewards: [-4827.28144587] --- Steps: 20\n",
      "Episode: 276 --- Rewards: [-2322.94087684] --- Steps: 20\n",
      "Episode: 277 --- Rewards: [-4963.30311333] --- Steps: 20\n",
      "Episode: 278 --- Rewards: [-6425.54042057] --- Steps: 20\n",
      "Episode: 279 --- Rewards: [-2908.90522362] --- Steps: 20\n",
      "Episode: 280 --- Rewards: [-4095.33073495] --- Steps: 20\n",
      "Episode: 281 --- Rewards: [-3351.62049525] --- Steps: 20\n",
      "Episode: 282 --- Rewards: [-3598.87686283] --- Steps: 20\n",
      "Episode: 283 --- Rewards: [-1215.45128674] --- Steps: 20\n",
      "Episode: 284 --- Rewards: [-1449.83125043] --- Steps: 20\n",
      "Episode: 285 --- Rewards: [-10696.40444812] --- Steps: 20\n",
      "Episode: 286 --- Rewards: [-3539.65875707] --- Steps: 20\n",
      "Episode: 287 --- Rewards: [-1698.73418304] --- Steps: 20\n",
      "Episode: 288 --- Rewards: [-917.04523683] --- Steps: 20\n",
      "Episode: 289 --- Rewards: [-5635.79214203] --- Steps: 20\n",
      "Episode: 290 --- Rewards: [-2050.71804626] --- Steps: 20\n",
      "Episode: 291 --- Rewards: [-859.72727536] --- Steps: 20\n",
      "Episode: 292 --- Rewards: [-1131.07926402] --- Steps: 20\n",
      "Episode: 293 --- Rewards: [-621.42872822] --- Steps: 20\n",
      "Episode: 294 --- Rewards: [-9592.69173025] --- Steps: 20\n",
      "Episode: 295 --- Rewards: [-10156.45664718] --- Steps: 20\n",
      "Episode: 296 --- Rewards: [-2421.41368566] --- Steps: 20\n",
      "Episode: 297 --- Rewards: [-3516.42595602] --- Steps: 20\n",
      "Episode: 298 --- Rewards: [-7603.97963524] --- Steps: 20\n",
      "Episode: 299 --- Rewards: [-1170.3414253] --- Steps: 20\n",
      "Episode: 300 --- Rewards: [-2704.58325295] --- Steps: 20\n",
      "Episode: 301 --- Rewards: [-2466.91118376] --- Steps: 20\n",
      "Episode: 302 --- Rewards: [-3290.77215971] --- Steps: 20\n",
      "Episode: 303 --- Rewards: [-2171.36064708] --- Steps: 20\n",
      "Episode: 304 --- Rewards: [-4480.88145553] --- Steps: 20\n",
      "Episode: 305 --- Rewards: [-8668.96700134] --- Steps: 20\n",
      "Episode: 306 --- Rewards: [-2918.95118481] --- Steps: 20\n",
      "Episode: 307 --- Rewards: [-6133.10592456] --- Steps: 20\n",
      "Episode: 308 --- Rewards: [-7032.9691927] --- Steps: 20\n",
      "Episode: 309 --- Rewards: [-11866.654791] --- Steps: 20\n",
      "Episode: 310 --- Rewards: [-5890.18914384] --- Steps: 20\n",
      "Episode: 311 --- Rewards: [-11466.32487372] --- Steps: 20\n",
      "Episode: 312 --- Rewards: [-8408.85861465] --- Steps: 20\n",
      "Episode: 313 --- Rewards: [-1725.20614246] --- Steps: 20\n",
      "Episode: 314 --- Rewards: [-541.64715545] --- Steps: 20\n",
      "Episode: 315 --- Rewards: [-3141.95659155] --- Steps: 20\n",
      "Episode: 316 --- Rewards: [-6293.49784217] --- Steps: 20\n",
      "Episode: 317 --- Rewards: [-3359.06448063] --- Steps: 20\n",
      "Episode: 318 --- Rewards: [-2212.6861902] --- Steps: 20\n",
      "Episode: 319 --- Rewards: [-7165.56144168] --- Steps: 20\n",
      "Episode: 320 --- Rewards: [-8247.13664593] --- Steps: 20\n",
      "Episode: 321 --- Rewards: [-2497.87949589] --- Steps: 20\n",
      "Episode: 322 --- Rewards: [-2770.18681194] --- Steps: 20\n",
      "Episode: 323 --- Rewards: [-2341.863326] --- Steps: 20\n",
      "Episode: 324 --- Rewards: [-1644.63173035] --- Steps: 20\n",
      "Episode: 325 --- Rewards: [-3848.25247305] --- Steps: 20\n",
      "Episode: 326 --- Rewards: [-290.81196406] --- Steps: 20\n",
      "Episode: 327 --- Rewards: [-1402.12251494] --- Steps: 20\n",
      "Episode: 328 --- Rewards: [-3043.7407307] --- Steps: 20\n",
      "Episode: 329 --- Rewards: [-10430.80624934] --- Steps: 20\n",
      "Episode: 330 --- Rewards: [-3316.07827522] --- Steps: 20\n",
      "Episode: 331 --- Rewards: [-6908.57359342] --- Steps: 20\n",
      "Episode: 332 --- Rewards: [-5167.91563393] --- Steps: 20\n",
      "Episode: 333 --- Rewards: [-815.76110334] --- Steps: 20\n",
      "Episode: 334 --- Rewards: [-3666.25741355] --- Steps: 20\n",
      "Episode: 335 --- Rewards: [-8456.89826533] --- Steps: 20\n",
      "Episode: 336 --- Rewards: [-7357.25205279] --- Steps: 20\n",
      "Episode: 337 --- Rewards: [-2275.592596] --- Steps: 20\n",
      "Episode: 338 --- Rewards: [-632.90409584] --- Steps: 20\n",
      "Episode: 339 --- Rewards: [-7632.31830617] --- Steps: 20\n",
      "Episode: 340 --- Rewards: [-3160.52924393] --- Steps: 20\n",
      "Episode: 341 --- Rewards: [-4716.19887868] --- Steps: 20\n",
      "Episode: 342 --- Rewards: [-6380.0271167] --- Steps: 20\n",
      "Episode: 343 --- Rewards: [-2641.78913061] --- Steps: 20\n",
      "Episode: 344 --- Rewards: [-12462.43471633] --- Steps: 20\n",
      "Episode: 345 --- Rewards: [-2436.63211088] --- Steps: 20\n",
      "Episode: 346 --- Rewards: [-3722.93215734] --- Steps: 20\n",
      "Episode: 347 --- Rewards: [-4702.65711921] --- Steps: 20\n",
      "Episode: 348 --- Rewards: [-4270.33673176] --- Steps: 20\n",
      "Episode: 349 --- Rewards: [-2154.69691054] --- Steps: 20\n",
      "Episode: 350 --- Rewards: [-3815.99051842] --- Steps: 20\n",
      "Episode: 351 --- Rewards: [-6641.67134925] --- Steps: 20\n",
      "Episode: 352 --- Rewards: [-8654.35870361] --- Steps: 20\n",
      "Episode: 353 --- Rewards: [-2581.15828033] --- Steps: 20\n",
      "Episode: 354 --- Rewards: [-1579.30797112] --- Steps: 20\n",
      "Episode: 355 --- Rewards: [-3094.33904271] --- Steps: 20\n",
      "Episode: 356 --- Rewards: [-1705.93542128] --- Steps: 20\n",
      "Episode: 357 --- Rewards: [-2391.69790541] --- Steps: 20\n",
      "Episode: 358 --- Rewards: [-3542.23299353] --- Steps: 20\n",
      "Episode: 359 --- Rewards: [-1823.73972965] --- Steps: 20\n",
      "Episode: 360 --- Rewards: [-3790.315471] --- Steps: 20\n",
      "Episode: 361 --- Rewards: [-7809.2355305] --- Steps: 20\n",
      "Episode: 362 --- Rewards: [-9669.32866425] --- Steps: 20\n",
      "Episode: 363 --- Rewards: [-961.94194974] --- Steps: 20\n",
      "Episode: 364 --- Rewards: [-4129.53545191] --- Steps: 20\n",
      "Episode: 365 --- Rewards: [-3061.45081931] --- Steps: 20\n",
      "Episode: 366 --- Rewards: [-2082.08621501] --- Steps: 20\n",
      "Episode: 367 --- Rewards: [-5226.75812764] --- Steps: 20\n",
      "Episode: 368 --- Rewards: [-1264.17816592] --- Steps: 20\n",
      "Episode: 369 --- Rewards: [-2214.34242933] --- Steps: 20\n",
      "Episode: 370 --- Rewards: [-3880.80663669] --- Steps: 20\n",
      "Episode: 371 --- Rewards: [-5000.52443465] --- Steps: 20\n",
      "Episode: 372 --- Rewards: [-2572.51297459] --- Steps: 20\n",
      "Episode: 373 --- Rewards: [-4952.61670258] --- Steps: 20\n",
      "Episode: 374 --- Rewards: [-327.62587563] --- Steps: 20\n",
      "Episode: 375 --- Rewards: [-4145.61382057] --- Steps: 20\n",
      "Episode: 376 --- Rewards: [-1052.02357117] --- Steps: 20\n",
      "Episode: 377 --- Rewards: [-3459.35837396] --- Steps: 20\n",
      "Episode: 378 --- Rewards: [-3079.48932173] --- Steps: 20\n",
      "Episode: 379 --- Rewards: [-7860.63877815] --- Steps: 20\n",
      "Episode: 380 --- Rewards: [-5325.71540828] --- Steps: 20\n",
      "Episode: 381 --- Rewards: [-918.14602191] --- Steps: 20\n",
      "Episode: 382 --- Rewards: [-5560.80015105] --- Steps: 20\n",
      "Episode: 383 --- Rewards: [-4473.5243485] --- Steps: 20\n",
      "Episode: 384 --- Rewards: [-1381.25688146] --- Steps: 20\n",
      "Episode: 385 --- Rewards: [-3599.54684713] --- Steps: 20\n",
      "Episode: 386 --- Rewards: [-5719.55648494] --- Steps: 20\n",
      "Episode: 387 --- Rewards: [-6270.03918611] --- Steps: 20\n",
      "Episode: 388 --- Rewards: [-2494.9315829] --- Steps: 20\n",
      "Episode: 389 --- Rewards: [-8664.99505417] --- Steps: 20\n",
      "Episode: 390 --- Rewards: [-3860.42624786] --- Steps: 20\n",
      "Episode: 391 --- Rewards: [-2991.91299884] --- Steps: 20\n",
      "Episode: 392 --- Rewards: [-2561.18199691] --- Steps: 20\n",
      "Episode: 393 --- Rewards: [-4839.45330731] --- Steps: 20\n",
      "Episode: 394 --- Rewards: [-11239.73858909] --- Steps: 20\n",
      "Episode: 395 --- Rewards: [-2046.05449416] --- Steps: 20\n",
      "Episode: 396 --- Rewards: [-1820.44952701] --- Steps: 20\n",
      "Episode: 397 --- Rewards: [-9444.56391254] --- Steps: 20\n",
      "Episode: 398 --- Rewards: [-10293.17137847] --- Steps: 20\n",
      "Episode: 399 --- Rewards: [-2238.7826917] --- Steps: 20\n",
      "Episode: 400 --- Rewards: [-5841.76810389] --- Steps: 20\n",
      "Episode: 401 --- Rewards: [-5826.73812369] --- Steps: 20\n",
      "Episode: 402 --- Rewards: [-356.79875438] --- Steps: 20\n",
      "Episode: 403 --- Rewards: [-1602.05220179] --- Steps: 20\n",
      "Episode: 404 --- Rewards: [-2755.41532078] --- Steps: 20\n",
      "Episode: 405 --- Rewards: [-3856.5448322] --- Steps: 20\n",
      "Episode: 406 --- Rewards: [-3790.92166987] --- Steps: 20\n",
      "Episode: 407 --- Rewards: [-6983.42607712] --- Steps: 20\n",
      "Episode: 408 --- Rewards: [-4211.91790645] --- Steps: 20\n",
      "Episode: 409 --- Rewards: [-3391.31474254] --- Steps: 20\n",
      "Episode: 410 --- Rewards: [-2789.6946724] --- Steps: 20\n",
      "Episode: 411 --- Rewards: [-3520.12908878] --- Steps: 20\n",
      "Episode: 412 --- Rewards: [-2487.87616162] --- Steps: 20\n",
      "Episode: 413 --- Rewards: [-6168.81589303] --- Steps: 20\n",
      "Episode: 414 --- Rewards: [-1687.16009228] --- Steps: 20\n",
      "Episode: 415 --- Rewards: [-9417.91130601] --- Steps: 20\n",
      "Episode: 416 --- Rewards: [-1978.55944954] --- Steps: 20\n",
      "Episode: 417 --- Rewards: [-5849.13921594] --- Steps: 20\n",
      "Episode: 418 --- Rewards: [-11541.44814657] --- Steps: 20\n",
      "Episode: 419 --- Rewards: [-4615.05747157] --- Steps: 20\n",
      "Episode: 420 --- Rewards: [-8670.30077486] --- Steps: 20\n",
      "Episode: 421 --- Rewards: [-4567.7137252] --- Steps: 20\n",
      "Episode: 422 --- Rewards: [-4515.72854147] --- Steps: 20\n",
      "Episode: 423 --- Rewards: [-3098.32054791] --- Steps: 20\n",
      "Episode: 424 --- Rewards: [-6048.00269812] --- Steps: 20\n",
      "Episode: 425 --- Rewards: [-2786.01226258] --- Steps: 20\n",
      "Episode: 426 --- Rewards: [-4660.85347287] --- Steps: 20\n",
      "Episode: 427 --- Rewards: [-2654.61683672] --- Steps: 20\n",
      "Episode: 428 --- Rewards: [-1719.41833458] --- Steps: 20\n",
      "Episode: 429 --- Rewards: [-2766.62860695] --- Steps: 20\n",
      "Episode: 430 --- Rewards: [-4799.57095499] --- Steps: 20\n",
      "Episode: 431 --- Rewards: [-7950.96802453] --- Steps: 20\n",
      "Episode: 432 --- Rewards: [-10918.25862654] --- Steps: 20\n",
      "Episode: 433 --- Rewards: [-5248.55092785] --- Steps: 20\n",
      "Episode: 434 --- Rewards: [-7185.05169814] --- Steps: 20\n",
      "Episode: 435 --- Rewards: [-9052.36732465] --- Steps: 20\n",
      "Episode: 436 --- Rewards: [-3110.97337196] --- Steps: 20\n",
      "Episode: 437 --- Rewards: [-855.74390419] --- Steps: 20\n",
      "Episode: 438 --- Rewards: [-4096.27688894] --- Steps: 20\n",
      "Episode: 439 --- Rewards: [-2151.19115455] --- Steps: 20\n",
      "Episode: 440 --- Rewards: [-6876.58570285] --- Steps: 20\n",
      "Episode: 441 --- Rewards: [-3742.59243508] --- Steps: 20\n",
      "Episode: 442 --- Rewards: [-1736.6380607] --- Steps: 20\n",
      "Episode: 443 --- Rewards: [-9049.02916035] --- Steps: 20\n",
      "Episode: 444 --- Rewards: [-5338.78825165] --- Steps: 20\n",
      "Episode: 445 --- Rewards: [-7040.91527866] --- Steps: 20\n",
      "Episode: 446 --- Rewards: [-405.19832495] --- Steps: 20\n",
      "Episode: 447 --- Rewards: [-1292.84145972] --- Steps: 20\n",
      "Episode: 448 --- Rewards: [-9348.87997415] --- Steps: 20\n",
      "Episode: 449 --- Rewards: [-738.07654415] --- Steps: 20\n",
      "Episode: 450 --- Rewards: [-7195.43418248] --- Steps: 20\n",
      "Episode: 451 --- Rewards: [-13115.06528467] --- Steps: 20\n",
      "Episode: 452 --- Rewards: [-5268.50133991] --- Steps: 20\n",
      "Episode: 453 --- Rewards: [-5585.49037973] --- Steps: 20\n",
      "Episode: 454 --- Rewards: [-4675.5435226] --- Steps: 20\n",
      "Episode: 455 --- Rewards: [-13334.06886529] --- Steps: 20\n",
      "Episode: 456 --- Rewards: [-15164.1918087] --- Steps: 20\n",
      "Episode: 457 --- Rewards: [-1542.86383505] --- Steps: 20\n",
      "Episode: 458 --- Rewards: [-7719.22287231] --- Steps: 20\n",
      "Episode: 459 --- Rewards: [-1570.75821705] --- Steps: 20\n",
      "Episode: 460 --- Rewards: [-3028.71931829] --- Steps: 20\n",
      "Episode: 461 --- Rewards: [-2025.65264247] --- Steps: 20\n",
      "Episode: 462 --- Rewards: [-10128.31603206] --- Steps: 20\n",
      "Episode: 463 --- Rewards: [-5644.24189502] --- Steps: 20\n",
      "Episode: 464 --- Rewards: [-5347.1262353] --- Steps: 20\n",
      "Episode: 465 --- Rewards: [-1545.8417519] --- Steps: 20\n",
      "Episode: 466 --- Rewards: [-3335.44468638] --- Steps: 20\n",
      "Episode: 467 --- Rewards: [-6072.28176087] --- Steps: 20\n",
      "Episode: 468 --- Rewards: [-4537.73030424] --- Steps: 20\n",
      "Episode: 469 --- Rewards: [-10610.90792599] --- Steps: 20\n",
      "Episode: 470 --- Rewards: [-2984.7925231] --- Steps: 20\n",
      "Episode: 471 --- Rewards: [-14186.67677577] --- Steps: 20\n",
      "Episode: 472 --- Rewards: [-1926.69120009] --- Steps: 20\n",
      "Episode: 473 --- Rewards: [-1704.13904178] --- Steps: 20\n",
      "Episode: 474 --- Rewards: [-2112.86778594] --- Steps: 20\n",
      "Episode: 475 --- Rewards: [-5649.79717852] --- Steps: 20\n",
      "Episode: 476 --- Rewards: [-3367.98775989] --- Steps: 20\n",
      "Episode: 477 --- Rewards: [-2978.91742403] --- Steps: 20\n",
      "Episode: 478 --- Rewards: [-10776.44182056] --- Steps: 20\n",
      "Episode: 479 --- Rewards: [-8451.57106462] --- Steps: 20\n",
      "Episode: 480 --- Rewards: [-3104.10733056] --- Steps: 20\n",
      "Episode: 481 --- Rewards: [-4952.83802427] --- Steps: 20\n",
      "Episode: 482 --- Rewards: [-3539.83712082] --- Steps: 20\n",
      "Episode: 483 --- Rewards: [-6163.23320265] --- Steps: 20\n",
      "Episode: 484 --- Rewards: [-2298.43624165] --- Steps: 20\n",
      "Episode: 485 --- Rewards: [-4128.93826578] --- Steps: 20\n",
      "Episode: 486 --- Rewards: [-4636.25108145] --- Steps: 20\n",
      "Episode: 487 --- Rewards: [-1609.72473942] --- Steps: 20\n",
      "Episode: 488 --- Rewards: [-2923.92393566] --- Steps: 20\n",
      "Episode: 489 --- Rewards: [-3203.98578277] --- Steps: 20\n",
      "Episode: 490 --- Rewards: [-4932.54230163] --- Steps: 20\n",
      "Episode: 491 --- Rewards: [-5209.23382799] --- Steps: 20\n",
      "Episode: 492 --- Rewards: [-2430.46109798] --- Steps: 20\n",
      "Episode: 493 --- Rewards: [-1578.48360795] --- Steps: 20\n",
      "Episode: 494 --- Rewards: [-10119.98952946] --- Steps: 20\n",
      "Episode: 495 --- Rewards: [-8374.93366447] --- Steps: 20\n",
      "Episode: 496 --- Rewards: [-12104.6948904] --- Steps: 20\n",
      "Episode: 497 --- Rewards: [-1835.07727334] --- Steps: 20\n",
      "Episode: 498 --- Rewards: [-7839.01911379] --- Steps: 20\n",
      "Episode: 499 --- Rewards: [-18966.74033925] --- Steps: 20\n",
      "Episode: 500 --- Rewards: [-1648.90201625] --- Steps: 20\n",
      "PF [0.]\n",
      "GD 130.69577468006213\n",
      "IGD 130.69577468006213\n",
      "final result X: [ 1.05126519  4.78753165  2.31624197 -0.19481423  4.33975041 13.57685742\n",
      " -4.49492928 -1.60009275 -8.29302424 10.12682738  9.5349942   0.48812369\n",
      " -0.32434565]\n",
      "final result CV: [62.79479055]\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Deep_Deterministic_policy_gradient(Algorithm):\n",
    "    def __init__(self,\n",
    "                 gamma=0.99,\n",
    "                 actor_alpha=0.01,\n",
    "                 critic_alpha=0.01,\n",
    "                 num_rounds=20,\n",
    "                 sampling=FloatRandomSampling(),\n",
    "                 repair=NoRepair(),\n",
    "                 memory_capacity=10000,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.actor_alpha = actor_alpha\n",
    "        self.critic_alpha = critic_alpha\n",
    "        self.gamma = gamma\n",
    "        self.memory_capacity = memory_capacity\n",
    "        self.pointer = 0\n",
    "        self.rewards = []\n",
    "        self.steps_taken = []\n",
    "        self.W_init = tf.random_normal_initializer(mean=0, stddev=0.3)\n",
    "        self.b_init = tf.constant_initializer(0.1)\n",
    "        self.initialization = Initialization(sampling)\n",
    "        self.survival = RankAndCrowdingSurvival()\n",
    "        self.crossover = SimulatedBinaryCrossover(n_offsprings=1)\n",
    "        self.num_rounds = num_rounds\n",
    "        self.repair = repair\n",
    "\n",
    "        \n",
    "    def get_actor(self,input_state_shape, name=''):\n",
    "        tl.layers.set_name_reuse(True)\n",
    "        input_layer = tl.layers.Input(input_state_shape, name='A_input')\n",
    "        layer = tl.layers.Dense(n_units=self.n_var, act=tf.nn.relu, W_init=self.W_init, b_init=self.b_init, name='A_l1')(input_layer)\n",
    "        #print(\"layer1\",layer)\n",
    "        layer = tl.layers.Dense(n_units=self.n_var, act=tf.nn.relu, W_init=self.W_init, b_init=self.b_init, name='A_l2')(layer)\n",
    "        #print(\"layer2\",layer)\n",
    "        layer = tl.layers.Dense(n_units=self.n_var, act=tf.nn.tanh, W_init=self.W_init, b_init=self.b_init, name='A_a')(layer)\n",
    "        #print(\"layer3\",layer)\n",
    "        layer = tl.layers.Lambda(lambda x: 0.5 * x)(layer)\n",
    "        #print(\"layer4\",layer)            \n",
    "        return tl.models.Model(inputs=input_layer, outputs=layer, name='Actor3' + name)\n",
    "            \n",
    "    def get_critic(self,input_state_shape, input_action_shape, name=''):\n",
    "        tl.layers.set_name_reuse(True)\n",
    "        s = tl.layers.Input(input_state_shape, name='C_s_input')\n",
    "        a = tl.layers.Input(input_action_shape, name='C_a_input')\n",
    "        x = tl.layers.Concat(1)([s, a])\n",
    "        x = tl.layers.Dense(n_units=self.n_var, act=tf.nn.relu, W_init=self.W_init, b_init=self.b_init, name='C_l1')(x)\n",
    "        x = tl.layers.Dense(n_units=self.n_var, act=tf.nn.relu, W_init=self.W_init, b_init=self.b_init, name='C_l2')(x)\n",
    "        x = tl.layers.Dense(n_units=1, W_init=self.W_init, b_init=self.b_init, name='C_out')(x)\n",
    "        return tl.models.Model(inputs=[s, a], outputs=x, name='Critic3' + name)\n",
    "            \n",
    "        \n",
    "\n",
    "    def copy_para(self,from_model, to_model):\n",
    "        for i, j in zip(from_model.trainable_weights, to_model.trainable_weights):\n",
    "            j.assign(i)\n",
    "        \n",
    "        \n",
    "\n",
    "    def ema_update(self):\n",
    "        paras = self.actor.trainable_weights + self.critic.trainable_weights    \n",
    "        self.ema.apply(paras)                                               \n",
    "        for i, j in zip(self.actor_target.trainable_weights + self.critic_target.trainable_weights, paras):\n",
    "            i.assign(self.ema.average(j))\n",
    "\n",
    "    def choose_action(self, s):\n",
    "        return self.actor(np.array([s], dtype=np.float32))[0]\n",
    "        \n",
    "    def learn(self):\n",
    "        indices = np.random.choice(self.memory_capacity, size=64)    \n",
    "        bt = self.memory[indices, :]                    \n",
    "        bs = bt[:, :self.s_dim]                        \n",
    "        ba = bt[:, self.s_dim:self.s_dim + self.n_var]  \n",
    "        br = bt[:, -self.s_dim - 1:-self.s_dim]        \n",
    "        bs_ = bt[:, -self.s_dim:]                     \n",
    "\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            a_ = self.actor_target(bs_)\n",
    "            q_ = self.critic_target([bs_, a_])\n",
    "            y = br + self.gamma * q_\n",
    "            q = self.critic([bs, ba])\n",
    "            td_error = tf.losses.mean_squared_error(y, q)\n",
    "        c_grads = tape.gradient(td_error, self.critic.trainable_weights)\n",
    "        self.critic_opt.apply_gradients(zip(c_grads, self.critic.trainable_weights))\n",
    "        self.ema_update()\n",
    "\n",
    "    def store_transition(self, s, a, r, s_):\n",
    "        \n",
    "        s = s.astype(np.float32)\n",
    "        s_ = s_.astype(np.float32)\n",
    "\n",
    "        transition = np.hstack((s, a, r, s_))\n",
    "\n",
    "        index = self.pointer % self.memory_capacity\n",
    "        self.memory[index, :] = transition\n",
    "        self.pointer += 1\n",
    "    \n",
    "    \n",
    "    def _setup(self, problem, **kwargs):\n",
    "        self.n_var = np.array(self.problem.n_var)\n",
    "        self.s_dim = np.array(self.n_var)\n",
    "        self.bound = np.array(self.problem.bounds())\n",
    "        self.memory = np.zeros((self.memory_capacity, self.s_dim * 2 + self.n_var + 1), dtype=np.float32)\n",
    "        self.actor = self.get_actor([None, self.s_dim])\n",
    "        self.critic = self.get_critic([None, self.s_dim], [None, self.n_var])\n",
    "        self.actor.train()\n",
    "        self.critic.train()\n",
    "        self.actor_target = self.get_actor([None, self.s_dim], name='_target')\n",
    "        self.copy_para(self.actor, self.actor_target)\n",
    "        self.actor_target.eval()\n",
    "\n",
    "        self.critic_target = self.get_critic([None, self.s_dim], [None, self.n_var], name='_target')\n",
    "        self.copy_para(self.critic, self.critic_target)\n",
    "        self.critic_target.eval()\n",
    "\n",
    "        self.R = tl.layers.Input([None, 1], tf.float32, 'r')\n",
    "\n",
    "        self.ema = tf.train.ExponentialMovingAverage(decay=1 - 0.01)  # soft replacement\n",
    "\n",
    "        self.actor_opt = tf.optimizers.Adam(self.actor_alpha)\n",
    "        self.critic_opt = tf.optimizers.Adam(self.critic_alpha)\n",
    "        \n",
    "    def _initialize_infill(self):\n",
    "        return self.initialization.do(self.problem, 1, algorithm=self)\n",
    "\n",
    "    def _initialize_advance(self, infills=None, **kwargs):\n",
    "        self.data_set_X = self.pop.get(\"X\")\n",
    "        #super()._initialize_advance(infills=infills, **kwargs)\n",
    "\n",
    "    def _infill(self):\n",
    "        state = self.get_starting_point()\n",
    "        #normalized_state = self.state_normalization(state)\n",
    "        termination_rounds = self.num_rounds \n",
    "        steps = 0\n",
    "        ep_reward = 0\n",
    "\n",
    "        while steps < termination_rounds:\n",
    "            #print(\"self.opt.get(F)\",self.opt.get(\"F\"))\n",
    "           # print(\"self.problem.evaluate(np.array(state))[0]\",self.problem.evaluate(np.array(state))[0])\n",
    "            #print(\"state\",state)\n",
    "            a = self.choose_action(np.array(state))\n",
    "            a = np.clip(np.random.normal(a, 3), -2, 2)  \n",
    "\n",
    "            new_state, reward = self.step(a,state)\n",
    "            self.store_transition(state, a, reward / 10, new_state)\n",
    "            if self.pointer > self.memory_capacity:\n",
    "                    self.learn()\n",
    "            \n",
    "            state = new_state\n",
    "            ep_reward += reward\n",
    "            steps +=1\n",
    "\n",
    "        #print(\"normalized_state2\",normalized_state)\n",
    "        self.data_set_X = np.vstack((self.data_set_X, state))\n",
    "        #print(\"self.data_set_X\",self.data_set_X)\n",
    "        off = Population.new(X=self.data_set_X, F = self.problem.evaluate(self.data_set_X, return_values_of=[\"F\"]))\n",
    "        self.pop = off\n",
    "        self.rewards.append(ep_reward)\n",
    "        self.steps_taken.append(steps)\n",
    "        print(\"Episode: {} --- Rewards: {} --- Steps: {}\".format(self.n_iter, ep_reward, steps))\n",
    "        return self.pop\n",
    "        \n",
    "    def _advance(self, infills=None, **kwargs):\n",
    "        return super()._advance(infills=infills, **kwargs)\n",
    "    \n",
    "    \n",
    "    def _finalize(self):\n",
    "        return super()._finalize()\n",
    "    \n",
    "    def get_rewards(self, current_state, new_state):\n",
    "            #print(\"current_state\",current_state)\n",
    "            #print(\"new_state\",new_state)\n",
    "            eucli_dist = self.problem.evaluate(current_state, return_values_of=[\"F\"]) - self.problem.evaluate(new_state, return_values_of=[\"F\"])\n",
    "            #print(\"self.problem.evaluate(new_state)[0]\",self.problem.evaluate(new_state)[0])\n",
    "            #print(\"self.problem.evaluate(current_state)[0]\",self.problem.evaluate(current_state)[0])\n",
    "            Y_cv = 0\n",
    "            Y_cv = self.problem.evaluate(new_state, return_values_of=[\"CV\"])    \n",
    "            if Y_cv.size > 0 or len(is_out_of_bounds_by_problem(self.problem, [new_state])) > 0:\n",
    "                return -3*eucli_dist# + self.penalty_function(new_state) + Y_cv**2)\n",
    "            elif eucli_dist < 0:\n",
    "                return -3*eucli_dist\n",
    "            elif eucli_dist > 0:\n",
    "                return 3*eucli_dist\n",
    "            elif eucli_dist == 0:\n",
    "                return -1\n",
    "            else:\n",
    "                return 1*eucli_dist\n",
    "    \n",
    "    def penalty_function(self, state):\n",
    "        return  np.sum(np.maximum(0, state - self.problem.xu)**2) + np.sum(np.maximum(0, self.problem.xl - state)**2)\n",
    "    \n",
    "    def get_starting_point(self):\n",
    "        if self.pop.size <= 2 or np.random.random_sample() > 0:\n",
    "            return self.initialization.do(self.problem, 1, algorithm=self).get(\"X\")[0]\n",
    "        else:\n",
    "            new_parents = self.survival.do(self.problem, self.pop, n_survive=2)\n",
    "            new_state = self.crossover.do(self.problem, [new_parents]).get(\"X\")[0]\n",
    "            return new_state\n",
    "    def state_normalization(self, state):\n",
    "        return (state - self.mean)/self.std\n",
    "\n",
    "\n",
    "\n",
    "    def step(self, action, state):\n",
    "        current_X = state\n",
    "        X_new = current_X + action\n",
    "        reward = 0\n",
    "        #print(\"current_X:\", current_X)\n",
    "        #print(\"action:\", action)\n",
    "        #while len(is_out_of_bounds_by_problem(self.problem, [X_new])) > 0:           \n",
    "        #    X_new = self.sampling.do(self.problem, 1, algorithm=self).get(\"X\")[0]\n",
    "        reward = self.get_rewards(current_X, X_new)\n",
    "        \n",
    "        \n",
    "        #if self.is_constraint_model or self.problem.n_eq_constr > 0:\n",
    "        #    Y_new = evlaution_of_new_points[0]\n",
    "        #    Constraint_new = evlaution_of_new_points[1]\n",
    "        #else:\n",
    "        \n",
    "        new_state = np.array(X_new)\n",
    "        #print(\"rewards\",reward)\n",
    "        return new_state, reward\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.problems import get_problem\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.indicators.gd import GD\n",
    "from pymoo.indicators.igd import IGD\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pymoo.algorithms.soo.nonconvex.pso import PSO\n",
    "from pymoo.algorithms.soo.nonconvex.ga import GA\n",
    "from pymoo.termination import get_termination\n",
    "from random import randint\n",
    "from pymoo.constraints.as_obj import ConstraintsAsObjective\n",
    "from pymoo.termination.ftol import SingleObjectiveSpaceTermination\n",
    "from pymoo.termination.robust import RobustTermination\n",
    "from pymoo.termination.default import DefaultMultiObjectiveTermination\n",
    "import random\n",
    "\n",
    "torch.manual_seed (2)\n",
    "\n",
    "problem = get_problem(\"ackley\", n_var=20, a=20, b=1/5, c=2 * np.pi)\n",
    "problem1 = get_problem(\"Rastrigin\", n_var=20)\n",
    "problem2 = get_problem(\"Rosenbrock\", n_var=20)\n",
    "problem3 = get_problem(\"g1\")\n",
    "algorithm3 = Deep_Deterministic_policy_gradient()\n",
    "res = minimize( problem3,\n",
    "                algorithm3,\n",
    "                save_history=False,\n",
    "                termination=('n_iter', 500),\n",
    "                seed = 2,\n",
    "                return_least_infeasible=True,\n",
    "                verbose=True)\n",
    "\n",
    "pf = problem2.pareto_front()\n",
    "print(\"PF\",pf[0])\n",
    "ind = GD(pf)\n",
    "print(\"GD\", ind(res.F))\n",
    "ind2 = IGD(pf)\n",
    "print(\"IGD\", ind2(res.F))\n",
    "\n",
    "\n",
    "n_evals = np.array([e.evaluator.n_eval for e in res.history])\n",
    "\n",
    "opt = np.array([e.opt[0].F for e in res.history])\n",
    "print(\"final result X:\",res.X)\n",
    "print(\"final result CV:\",res.CV)\n",
    "print(opt)\n",
    "plt.title(\"Convergence\")\n",
    "plt.plot(n_evals, opt, \"--\")\n",
    "plt.plot(n_evals, np.repeat(pf[0],len(n_evals)), 'k-', lw=1,dashes=[2, 2])\n",
    "#plt.yscale(\"log\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
