{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Policy(nn.Module):\n",
    "  def __init__(self,input_shape):\n",
    "    super().__init__()\n",
    "    print(\"input_shape\",input_shape)\n",
    "    self.model = nn.Sequential(\n",
    "        nn.Linear(input_shape[0],64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64,32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32,input_shape[0]),\n",
    "    )\n",
    "  def forward(self,x):\n",
    "    return self.model(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.core.algorithm import Algorithm\n",
    "from pymoo.operators.sampling.rnd import FloatRandomSampling\n",
    "from torch.distributions import Normal\n",
    "from pymoo.core.initialization import Initialization\n",
    "from pymoo.core.population import Population\n",
    "from pymoo.operators.repair.bounds_repair import is_out_of_bounds_by_problem\n",
    "from pymoo.core.repair import NoRepair\n",
    "from torch import optim\n",
    "import torch\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "from pymoo.util.optimum import filter_optimum\n",
    "\n",
    "class MonteCarloGradientPolicyAlgorithm(Algorithm):\n",
    "    def __init__(self,\n",
    "                 gamma=0.99,\n",
    "                 alpha=0.01,\n",
    "                 num_rounds=500,\n",
    "                 sample_size=500,\n",
    "                 sampling=FloatRandomSampling(),\n",
    "                 repair=NoRepair(),\n",
    "                 **kwargs):\n",
    "        \n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        env : \n",
    "            The environment to be used in the algorithm.\n",
    "        policy : {Policy}\n",
    "            The policy to be used in the algorithm.\n",
    "        gamma : float, optional\n",
    "            The discount factor used in the algorithm. The default is 0.99.\n",
    "        alpha : float, optional\n",
    "            The learning rate used in the algorithm. The default is 0.01.\n",
    "        num_episodes : int, optional\n",
    "            The number of episodes to be run in the algorithm. The default is 100.\n",
    "        sample_size : int, optional\n",
    "            The number of samples to be generated from the problems and used in the acquisition function. \n",
    "            The default is 10.\n",
    "        sampling : {Sampling}, optional\n",
    "            The sampling method used to generate the initial samples. The default is FloatRandomSampling().\n",
    "        \"\"\"\n",
    "         \n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.num_rounds = num_rounds\n",
    "        self.sample_size = sample_size\n",
    "        self.sampling = sampling\n",
    "        self.repair = repair\n",
    "        \n",
    "        self.initialization = Initialization(sampling)\n",
    "        self.is_constraint_model = False\n",
    "        self.optimizer = None\n",
    "        self.data_set_X = None\n",
    "        self.model = None\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.probs = []\n",
    "        self.rewards = []\n",
    "        self.steps_taken = []\n",
    "\n",
    "    def _setup(self, problem, **kwargs):\n",
    "        self.is_constraint_model = False\n",
    "        self.model = Policy(np.array([self.problem.n_var]))\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr = 1e-2)\n",
    "        \n",
    "    def _initialize_infill(self):\n",
    "        return self.initialization.do(self.problem, 1, algorithm=self)\n",
    "\n",
    "    def _initialize_advance(self, infills=None, **kwargs):\n",
    "        self.data_set_X = self.pop.get(\"X\")\n",
    "        #super()._initialize_advance(infills=infills, **kwargs)\n",
    "\n",
    "    def _infill(self):\n",
    "        state = self.sampling.do(self.problem, 1, algorithm=self).get(\"X\")[0]\n",
    "        self.num_rounds = 500\n",
    "        steps = 0\n",
    "        ep_rewards = 0\n",
    "        batch_rewards = []\n",
    "        log_probs = []\n",
    "\n",
    "        while steps < self.num_rounds:\n",
    "            #print(\"self.opt.get(F)\",self.opt.get(\"F\"))\n",
    "           # print(\"self.problem.evaluate(np.array(state))[0]\",self.problem.evaluate(np.array(state))[0])\n",
    "            a, log_p = self.action(self.model, torch.Tensor(state).unsqueeze(0))\n",
    "            log_probs.append(log_p)\n",
    "            new_state, reward = self.step(a,state)\n",
    "            batch_rewards.append(reward)\n",
    "            ep_rewards += reward\n",
    "            steps +=1\n",
    "            #print(\"state:\", state)\n",
    "            state = new_state\n",
    "            if steps + 1 == self.num_rounds and np.any(batch_rewards[-100:]) and self.num_rounds < 15000:\n",
    "                #print(\"steps:\", steps)\n",
    "                #print(\"batch_rewards[-100:]\", batch_rewards[-100:])\n",
    "                self.num_rounds += 100\n",
    "        \n",
    "        self.rewards.append(ep_rewards)\n",
    "        self.steps_taken.append(steps)\n",
    "        print(\"Episode: {} --- Rewards: {} --- Steps: {}\".format(self.n_iter, ep_rewards, steps))\n",
    "        self.update_policy(self.n_iter, self.optimizer, batch_rewards, log_probs)\n",
    "\n",
    "        \n",
    "        return self.pop\n",
    "        \n",
    "    def _advance(self, infills=None, **kwargs):\n",
    "        return super()._advance(infills=infills, **kwargs)\n",
    "    \n",
    "    \n",
    "    def _finalize(self):\n",
    "        return super()._finalize()\n",
    "    \n",
    "    def action(self, model, s):\n",
    "        # simple pytorch aproach for action-selection and log-prob calc \n",
    "        action_parameters = model(s)\n",
    "        #print(\"action_parameters:\", action_parameters)\n",
    "        #m = Categorical(prob)\n",
    "        #print(\"action_parameters[:, :1]:\", action_parameters[:, :1])\n",
    "        #print(\"action_parameters[:, 1:]:\", action_parameters[:, 1:])\n",
    "        #mu, sigma = action_parameters[:, :1], torch.exp(action_parameters[:, 1:])\n",
    "        mu, c = action_parameters[:, :1], 1\n",
    "        #print(\"mu:\", mu)\n",
    "        \n",
    "        m = Normal(action_parameters, torch.Tensor([np.tile([1],self.problem.n_var)]))\n",
    "        #print(\"m:\", m)\n",
    "        a = m.sample()\n",
    "        #print(\"a:\", a.tolist())\n",
    "        # log p(a∣π(s))\n",
    "        log_p = m.log_prob(a)\n",
    "        #print(\"log_p:\", log_p)\n",
    "        #print(a.item(), log_p)\n",
    "        return a.tolist(), log_p\n",
    "    \n",
    "    def step(self, action: np.ndarray, state):\n",
    "        current_X = state\n",
    "        X_new = current_X[0] + action[0]\n",
    "        reward = 0\n",
    "        #print(\"current_X:\", current_X)\n",
    "        #print(\"action:\", action)\n",
    "        while len(is_out_of_bounds_by_problem(self.problem, [X_new])) > 0:           \n",
    "            X_new = self.sampling.do(self.problem, 1, algorithm=self).get(\"X\")[0]\n",
    "        evlaution_of_new_points = self.problem.evaluate(np.array(X_new))\n",
    "        Y_new = evlaution_of_new_points[0]    \n",
    "        if Y_new < self.opt.get(\"F\"):\n",
    "            reward = self.opt.get(\"F\")[0][0] - Y_new\n",
    "            print(\"self.opt.get()[0][0]:\",self.opt.get(\"F\")[0][0])\n",
    "            self.data_set_X = np.vstack((self.data_set_X, X_new))\n",
    "            off = Population.new(X=self.data_set_X, F = self.problem.evaluate(self.data_set_X))\n",
    "            self.pop = off\n",
    "            print(\"self.pop\",self.pop.get(\"F\"))\n",
    "            self.opt = filter_optimum(self.pop, least_infeasible=True)\n",
    "            self.repair(self.problem, off)\n",
    "\n",
    "        \n",
    "        \n",
    "        #if self.is_constraint_model or self.problem.n_eq_constr > 0:\n",
    "        #    Y_new = evlaution_of_new_points[0]\n",
    "        #    Constraint_new = evlaution_of_new_points[1]\n",
    "        #else:\n",
    "        \n",
    "        state = np.array(X_new)\n",
    "        #print(\"rewards\",reward)\n",
    "        return state, reward\n",
    "    \n",
    "    def update_policy(self, ep, optimizer,batch_rewards,log_probs):\n",
    "        R = 0\n",
    "        gamma = 0.99\n",
    "        policy_loss = []\n",
    "        rewards = []\n",
    "        #calc discounted Rewards\n",
    "        for r in batch_rewards[::-1]: # reverses the list of rewards \n",
    "            R = r + gamma * R\n",
    "            rewards.insert(0, R) # inserts the current reward to first position\n",
    "        \n",
    "        #print(\"rewards\",rewards)\n",
    "        rewards = torch.tensor(rewards)\n",
    "        # standardization to get data of zero mean and varianz 1, stabilizes learning \n",
    "        #-- attention scaling rewards looses information of special events with higher rewards - addapting on different environments  \n",
    "        rewards = (rewards - rewards.mean()) / (rewards.std() + ep)\n",
    "        for log_prob, reward in zip(log_probs, rewards):\n",
    "            policy_loss.append(-log_prob * reward) #baseline+\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        policy_loss = torch.cat(policy_loss).sum()\n",
    "        policy_loss.backward()\n",
    "        optimizer.step()\n",
    "        \"\"\"G = 0\n",
    "        for t in reversed(range(len(states))):\n",
    "            G = self.gamma * G + rewards[t]\n",
    "            state = states[t]\n",
    "            action = actions[t]\n",
    "            grad_log_prob = self.policy.grad_log_prob(state, action)\n",
    "            self.policy.theta += self.alpha * G * grad_log_prob\"\"\"\n",
    "\n",
    "    \"\"\"def run_episode(self):\n",
    "        states = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        state = self.env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = self.policy.sample_action(state)\n",
    "            next_state, reward, done, _ = self.env.step(action)\n",
    "            states.append(state)\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            state = next_state\n",
    "        return states, actions, rewards\"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape [20]\n",
      "self.opt.get()[0][0]: 265.65469583797477\n",
      "self.pop [[265.65469584]\n",
      " [201.4681554 ]]\n",
      "self.opt.get()[0][0]: 201.46815540135668\n",
      "self.pop [[265.65469584]\n",
      " [201.4681554 ]\n",
      " [182.90124039]]\n",
      "self.opt.get()[0][0]: 182.90124039031733\n",
      "self.pop [[265.65469584]\n",
      " [201.4681554 ]\n",
      " [182.90124039]\n",
      " [182.08174575]]\n",
      "self.opt.get()[0][0]: 182.0817457506304\n",
      "self.pop [[265.65469584]\n",
      " [201.4681554 ]\n",
      " [182.90124039]\n",
      " [182.08174575]\n",
      " [160.77766147]]\n",
      "self.opt.get()[0][0]: 160.7776614666466\n",
      "self.pop [[265.65469584]\n",
      " [201.4681554 ]\n",
      " [182.90124039]\n",
      " [182.08174575]\n",
      " [160.77766147]\n",
      " [157.17618115]]\n",
      "self.opt.get()[0][0]: 157.17618114881452\n",
      "self.pop [[265.65469584]\n",
      " [201.4681554 ]\n",
      " [182.90124039]\n",
      " [182.08174575]\n",
      " [160.77766147]\n",
      " [157.17618115]\n",
      " [138.49206125]]\n",
      "Episode: 2 --- Rewards: 127.1626345892478 --- Steps: 1000\n",
      "Episode: 3 --- Rewards: 0 --- Steps: 1000\n",
      "self.opt.get()[0][0]: 138.49206124872697\n",
      "self.pop [[265.65469584]\n",
      " [201.4681554 ]\n",
      " [182.90124039]\n",
      " [182.08174575]\n",
      " [160.77766147]\n",
      " [157.17618115]\n",
      " [138.49206125]\n",
      " [129.30534882]]\n",
      "Episode: 4 --- Rewards: 9.18671243073041 --- Steps: 1000\n",
      "self.opt.get()[0][0]: 129.30534881799656\n",
      "self.pop [[265.65469584]\n",
      " [201.4681554 ]\n",
      " [182.90124039]\n",
      " [182.08174575]\n",
      " [160.77766147]\n",
      " [157.17618115]\n",
      " [138.49206125]\n",
      " [129.30534882]\n",
      " [124.34160213]]\n",
      "self.opt.get()[0][0]: 124.3416021289202\n",
      "self.pop [[265.65469584]\n",
      " [201.4681554 ]\n",
      " [182.90124039]\n",
      " [182.08174575]\n",
      " [160.77766147]\n",
      " [157.17618115]\n",
      " [138.49206125]\n",
      " [129.30534882]\n",
      " [124.34160213]\n",
      " [118.61652234]]\n",
      "Episode: 5 --- Rewards: 10.688826475954599 --- Steps: 1000\n",
      "Episode: 6 --- Rewards: 0 --- Steps: 1000\n",
      "self.opt.get()[0][0]: 118.61652234204196\n",
      "self.pop [[265.65469584]\n",
      " [201.4681554 ]\n",
      " [182.90124039]\n",
      " [182.08174575]\n",
      " [160.77766147]\n",
      " [157.17618115]\n",
      " [138.49206125]\n",
      " [129.30534882]\n",
      " [124.34160213]\n",
      " [118.61652234]\n",
      " [ 98.63267883]]\n",
      "Episode: 7 --- Rewards: 19.983843516391545 --- Steps: 1000\n",
      "Episode: 8 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 9 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 10 --- Rewards: 0 --- Steps: 1000\n",
      "self.opt.get()[0][0]: 98.63267882565042\n",
      "self.pop [[265.65469584]\n",
      " [201.4681554 ]\n",
      " [182.90124039]\n",
      " [182.08174575]\n",
      " [160.77766147]\n",
      " [157.17618115]\n",
      " [138.49206125]\n",
      " [129.30534882]\n",
      " [124.34160213]\n",
      " [118.61652234]\n",
      " [ 98.63267883]\n",
      " [ 91.98922323]]\n",
      "Episode: 11 --- Rewards: 6.643455596445577 --- Steps: 1000\n",
      "Episode: 12 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 13 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 14 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 15 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 16 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 17 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 18 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 19 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 20 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 21 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 22 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 23 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 24 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 25 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 26 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 27 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 28 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 29 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 30 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 31 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 32 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 33 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 34 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 35 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 36 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 37 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 38 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 39 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 40 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 41 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 42 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 43 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 44 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 45 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 46 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 47 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 48 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 49 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 50 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 51 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 52 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 53 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 54 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 55 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 56 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 57 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 58 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 59 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 60 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 61 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 62 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 63 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 64 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 65 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 66 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 67 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 68 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 69 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 70 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 71 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 72 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 73 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 74 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 75 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 76 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 77 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 78 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 79 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 80 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 81 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 82 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 83 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 84 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 85 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 86 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 87 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 88 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 89 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 90 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 91 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 92 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 93 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 94 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 95 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 96 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 97 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 98 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 99 --- Rewards: 0 --- Steps: 1000\n",
      "Episode: 100 --- Rewards: 0 --- Steps: 1000\n",
      "PF [0]\n",
      "GD 91.98922322920484\n",
      "IGD 91.98922322920484\n",
      "[[265.65469584]\n",
      " [138.49206125]\n",
      " [138.49206125]\n",
      " [129.30534882]\n",
      " [118.61652234]\n",
      " [118.61652234]\n",
      " [ 98.63267883]\n",
      " [ 98.63267883]\n",
      " [ 98.63267883]\n",
      " [ 98.63267883]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]\n",
      " [ 91.98922323]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pymoo.problems import get_problem\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.indicators.gd import GD\n",
    "from pymoo.indicators.igd import IGD\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pymoo.algorithms.soo.nonconvex.pso import PSO\n",
    "from pymoo.algorithms.soo.nonconvex.ga import GA\n",
    "from pymoo.termination import get_termination\n",
    "from random import randint\n",
    "from pymoo.constraints.as_obj import ConstraintsAsObjective\n",
    "from pymoo.termination.ftol import SingleObjectiveSpaceTermination\n",
    "from pymoo.termination.robust import RobustTermination\n",
    "from pymoo.termination.default import DefaultMultiObjectiveTermination\n",
    "import random\n",
    "\n",
    "torch.manual_seed (1)\n",
    "\n",
    "problem = get_problem(\"ackley\", n_var=2, a=20, b=1/5, c=2 * np.pi)\n",
    "problem1 = get_problem(\"Rastrigin\", n_var=20)\n",
    "algorithm3 = MonteCarloGradientPolicyAlgorithm()\n",
    "res = minimize( problem1,\n",
    "                algorithm3,\n",
    "                save_history=True,\n",
    "                termination=('n_iter', 100),\n",
    "                seed = 2,\n",
    "                return_least_infeasible=True,\n",
    "                verbose=True)\n",
    "\n",
    "pf = problem.pareto_front()\n",
    "print(\"PF\",pf[0])\n",
    "ind = GD(pf)\n",
    "print(\"GD\", ind(res.F))\n",
    "ind2 = IGD(pf)\n",
    "print(\"IGD\", ind2(res.F))\n",
    "\n",
    "\n",
    "n_evals = np.array([e.evaluator.n_eval for e in res.history])\n",
    "opt = np.array([e.opt[0].F for e in res.history])\n",
    "print(opt)\n",
    "plt.title(\"Convergence\")\n",
    "plt.plot(n_evals, opt, \"--\")\n",
    "plt.plot(n_evals, np.repeat(pf[0],len(n_evals)), 'k-', lw=1,dashes=[2, 2])\n",
    "#plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "i= np.where([-601\n",
    "             ,-601] < problem1.bounds()[0])\n",
    "print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 7, 9]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [12,4,6,7,9]\n",
    "l[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
